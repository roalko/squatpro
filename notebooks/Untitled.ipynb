{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "peaceful-reducing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, layers, optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "behavioral-style",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 65 CSVs in ../raw_data/Out_Feature_CSVs/Train/Bad Directory\n",
      "Found 65 CSVs in ../raw_data/Out_Feature_CSVs/Train/Good Directory\n",
      "Number of csvs : 130\n",
      "Number of Labels : 130\n",
      "Found 17 CSVs in ../raw_data/Out_Feature_CSVs/Test/Bad Directory\n",
      "Found 17 CSVs in ../raw_data/Out_Feature_CSVs/Test/Good Directory\n",
      "Number of csvs : 34\n",
      "Number of Labels : 34\n"
     ]
    }
   ],
   "source": [
    "ROOT_DATA_DIR = '../raw_data/Out_Feature_CSVs'\n",
    "#ROOT_DATA_DIR = '../raw_data/Out_Feature_CSVs'\n",
    "DATA_SUB_DIRs = [\"Train\", \"Test\"]\n",
    "CLS_LIST = [\"Bad\", \"Good\"]\n",
    "\n",
    "def get_y(data_path, class_list):\n",
    "    \n",
    "    data_dict = {\"csv_paths\":[], \"csv_files\":[], \"labels\":[]}\n",
    "    for i, clss in enumerate(class_list):\n",
    "        dir_path = os.path.join(data_path, clss)\n",
    "        list_csvs = [l for l in os.listdir(dir_path) if l.split(\".\")[-1]==\"csv\"]\n",
    "        print(f\"Found {len(list_csvs)} CSVs in {dir_path} Directory\")\n",
    "        data_dict[\"csv_files\"].extend(list_csvs)\n",
    "        data_dict[\"labels\"].extend([i for k in range(len(list_csvs))])\n",
    "        data_dict[\"csv_paths\"].extend([dir_path for _ in range(len(list_csvs))])\n",
    "    total_csvs = len(data_dict[\"csv_files\"])\n",
    "    total_labels = len(data_dict[\"labels\"])\n",
    "    print(f\"Number of csvs : {total_csvs}\")\n",
    "    print(f\"Number of Labels : {total_labels}\")\n",
    "    return data_dict\n",
    "\n",
    "train_data = pd.DataFrame(get_y(data_path=os.path.join(ROOT_DATA_DIR, DATA_SUB_DIRs[0]),\n",
    "                               class_list=CLS_LIST))\n",
    "\n",
    "\n",
    "test_data = pd.DataFrame(get_y(data_path=os.path.join(ROOT_DATA_DIR, DATA_SUB_DIRs[1]),\n",
    "                               class_list=CLS_LIST))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "trained-commerce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>csv_paths</th>\n",
       "      <th>csv_files</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../raw_data/Out_Feature_CSVs/Train/Bad</td>\n",
       "      <td>IMG_9347_03.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../raw_data/Out_Feature_CSVs/Train/Bad</td>\n",
       "      <td>IMG_9336_03.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../raw_data/Out_Feature_CSVs/Train/Bad</td>\n",
       "      <td>54.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../raw_data/Out_Feature_CSVs/Train/Bad</td>\n",
       "      <td>IMG_9451_02.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../raw_data/Out_Feature_CSVs/Train/Bad</td>\n",
       "      <td>IMG_9451_03.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                csv_paths        csv_files  labels\n",
       "0  ../raw_data/Out_Feature_CSVs/Train/Bad  IMG_9347_03.csv       0\n",
       "1  ../raw_data/Out_Feature_CSVs/Train/Bad  IMG_9336_03.csv       0\n",
       "2  ../raw_data/Out_Feature_CSVs/Train/Bad           54.csv       0\n",
       "3  ../raw_data/Out_Feature_CSVs/Train/Bad  IMG_9451_02.csv       0\n",
       "4  ../raw_data/Out_Feature_CSVs/Train/Bad  IMG_9451_03.csv       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "suffering-cause",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create y_train and y_test as float64 type\n",
    "y_train = train_data['labels']/1.0\n",
    "y_test = test_data['labels']/1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "macro-madison",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_list_of_lists(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.fillna(0, inplace=True)\n",
    "    list_of_lists = df.iloc[:,1:].values.tolist()\n",
    "    return list_of_lists\n",
    "\n",
    "def get_x(dataframe):\n",
    "  list_of_csv_files = [os.path.join(row['csv_paths'], row[\"csv_files\"]) for index, row in dataframe.iterrows()]\n",
    "  X_list = [csv_to_list_of_lists(f) for f in list_of_csv_files]\n",
    "  return X_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "imperial-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create X_train and X_test\n",
    "X_train = get_x(train_data)\n",
    "X_test = get_x(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "collectible-director",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130, 175, 2048)\n",
      "(34, 175, 2048)\n"
     ]
    }
   ],
   "source": [
    "#pad X_train so all arrays are of the same shape\n",
    "X_train_pad = pad_sequences(X_train, dtype='float32', padding='post', value=-1000)\n",
    "print(X_train_pad.shape)\n",
    "\n",
    "#pad X_test so all arrays are of the same shape\n",
    "X_test_pad = pad_sequences(X_test, dtype='float32', padding='post', value=-1000, maxlen=X_train_pad.shape[1])\n",
    "print(X_test_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sonic-lewis",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "prime-limitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_neurons=[256,128,64]\n",
    "neurons=[64,32,16]\n",
    "hyperparams = itertools.product(lstm_neurons,neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "provincial-verification",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "  rmsprop = optimizers.RMSprop(lr=0.0001)\n",
    "  model_LSTM = Sequential()\n",
    "  model_LSTM.add(layers.Masking(mask_value=-1000, input_shape=input_shape))\n",
    "  model_LSTM.add(layers.LSTM(128, activation='tanh', return_sequences=True))\n",
    "  model_LSTM.add(layers.Dropout(0.2))\n",
    "  model_LSTM.add(layers.LSTM(64, activation='tanh'))\n",
    "  model_LSTM.add(layers.Dense(64, activation='relu'))\n",
    "  model_LSTM.add(layers.Dense(32, activation='relu'))\n",
    "  model_LSTM.add(layers.Dense(16, activation='relu'))\n",
    "  model_LSTM.add(layers.Dense(8, activation='relu'))\n",
    "  model_LSTM.add(layers.Dense(4, activation='relu'))\n",
    "  model_LSTM.add(layers.Dense(2, activation='relu'))\n",
    "  model_LSTM.add(layers.Dense(1, activation='sigmoid'))\n",
    "  model_LSTM.compile(loss='binary_crossentropy', optimizer=rmsprop,metrics='accuracy')\n",
    "  return model_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "alike-graham",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 118ms/step - loss: 0.4371 - accuracy: 0.9077\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6514 - accuracy: 0.6471\n",
      "train=0.9076923131942749, test= 0.6470588445663452\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.4383 - accuracy: 0.8923\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.7297 - accuracy: 0.7059\n",
      "train=0.892307698726654, test= 0.7058823704719543\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.6932 - accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.6932 - accuracy: 0.5000\n",
      "train=0.5, test= 0.5\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.4022 - accuracy: 0.9385\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5526 - accuracy: 0.7647\n",
      "train=0.9384615421295166, test= 0.7647058963775635\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.4255 - accuracy: 0.9077\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5787 - accuracy: 0.6765\n",
      "train=0.9076923131942749, test= 0.6764705777168274\n"
     ]
    }
   ],
   "source": [
    "#Fitting the model to the train set\n",
    "for i in range(5):\n",
    "    model = build_model(input_shape=(X_train_pad.shape[1], X_train_pad.shape[2]))\n",
    "    es = EarlyStopping(patience=20)\n",
    "\n",
    "    model.fit(X_train_pad, y_train, \n",
    "              epochs=500, \n",
    "              batch_size=32, \n",
    "              verbose=0, \n",
    "              callbacks = [es],\n",
    "              validation_split=0.2,\n",
    "              shuffle=True)\n",
    "    print(f'train={model.evaluate(X_train_pad, y_train)[1]}, test= {model.evaluate(X_test_pad, y_test)[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "detected-guide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 136ms/step - loss: 0.4255 - accuracy: 0.9077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.42553606629371643, 0.9076923131942749]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate the model on the train set\n",
    "model.evaluate(X_train_pad, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "shaped-literacy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5787 - accuracy: 0.6765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5786683559417725, 0.6764705777168274]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate the model on the test set\n",
    "model.evaluate(X_test_pad, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "distant-topic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4800888 ],\n",
       "       [0.4800888 ],\n",
       "       [0.5174011 ],\n",
       "       [0.5022851 ],\n",
       "       [0.4800888 ],\n",
       "       [0.4800888 ],\n",
       "       [0.4800888 ],\n",
       "       [0.95042264],\n",
       "       [0.4800888 ],\n",
       "       [0.4800888 ],\n",
       "       [0.4800888 ],\n",
       "       [0.4800888 ],\n",
       "       [0.4800888 ],\n",
       "       [0.6670113 ],\n",
       "       [0.5424812 ],\n",
       "       [0.5192611 ],\n",
       "       [0.5536526 ],\n",
       "       [0.4800888 ],\n",
       "       [0.9501583 ],\n",
       "       [0.7663051 ],\n",
       "       [0.48369762],\n",
       "       [0.9516977 ],\n",
       "       [0.8494618 ],\n",
       "       [0.91676307],\n",
       "       [0.5069054 ],\n",
       "       [0.9512907 ],\n",
       "       [0.4800888 ],\n",
       "       [0.4800888 ],\n",
       "       [0.84109205],\n",
       "       [0.9304563 ],\n",
       "       [0.55009866],\n",
       "       [0.95159733],\n",
       "       [0.9516989 ],\n",
       "       [0.935415  ]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predictions of the test set compared to the actuals\n",
    "model.predict(X_test_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "empty-liberal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.0\n",
       "1     0.0\n",
       "2     0.0\n",
       "3     0.0\n",
       "4     0.0\n",
       "5     0.0\n",
       "6     0.0\n",
       "7     0.0\n",
       "8     0.0\n",
       "9     0.0\n",
       "10    0.0\n",
       "11    0.0\n",
       "12    0.0\n",
       "13    0.0\n",
       "14    0.0\n",
       "15    0.0\n",
       "16    0.0\n",
       "17    1.0\n",
       "18    1.0\n",
       "19    1.0\n",
       "20    1.0\n",
       "21    1.0\n",
       "22    1.0\n",
       "23    1.0\n",
       "24    1.0\n",
       "25    1.0\n",
       "26    1.0\n",
       "27    1.0\n",
       "28    1.0\n",
       "29    1.0\n",
       "30    1.0\n",
       "31    1.0\n",
       "32    1.0\n",
       "33    1.0\n",
       "Name: labels, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "anticipated-advice",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"my_model\")\n",
    "#model.save_weights(\"weights.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
