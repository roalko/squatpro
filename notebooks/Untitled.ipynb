{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "horizontal-credits",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, layers, optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "secondary-philadelphia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 65 CSVs in ../raw_data/Out_Feature_CSVs/Train/Bad Directory\n",
      "Found 65 CSVs in ../raw_data/Out_Feature_CSVs/Train/Good Directory\n",
      "Number of csvs : 130\n",
      "Number of Labels : 130\n",
      "Found 17 CSVs in ../raw_data/Out_Feature_CSVs/Test/Bad Directory\n",
      "Found 17 CSVs in ../raw_data/Out_Feature_CSVs/Test/Good Directory\n",
      "Number of csvs : 34\n",
      "Number of Labels : 34\n"
     ]
    }
   ],
   "source": [
    "ROOT_DATA_DIR = '../raw_data/Out_Feature_CSVs'\n",
    "#ROOT_DATA_DIR = '../raw_data/Out_Feature_CSVs'\n",
    "DATA_SUB_DIRs = [\"Train\", \"Test\"]\n",
    "CLS_LIST = [\"Bad\", \"Good\"]\n",
    "\n",
    "def get_y(data_path, class_list):\n",
    "    \n",
    "    data_dict = {\"csv_paths\":[], \"csv_files\":[], \"labels\":[]}\n",
    "    for i, clss in enumerate(class_list):\n",
    "        dir_path = os.path.join(data_path, clss)\n",
    "        list_csvs = [l for l in os.listdir(dir_path) if l.split(\".\")[-1]==\"csv\"]\n",
    "        print(f\"Found {len(list_csvs)} CSVs in {dir_path} Directory\")\n",
    "        data_dict[\"csv_files\"].extend(list_csvs)\n",
    "        data_dict[\"labels\"].extend([i for k in range(len(list_csvs))])\n",
    "        data_dict[\"csv_paths\"].extend([dir_path for _ in range(len(list_csvs))])\n",
    "    total_csvs = len(data_dict[\"csv_files\"])\n",
    "    total_labels = len(data_dict[\"labels\"])\n",
    "    print(f\"Number of csvs : {total_csvs}\")\n",
    "    print(f\"Number of Labels : {total_labels}\")\n",
    "    return data_dict\n",
    "\n",
    "train_data = pd.DataFrame(get_y(data_path=os.path.join(ROOT_DATA_DIR, DATA_SUB_DIRs[0]),\n",
    "                               class_list=CLS_LIST))\n",
    "\n",
    "\n",
    "test_data = pd.DataFrame(get_y(data_path=os.path.join(ROOT_DATA_DIR, DATA_SUB_DIRs[1]),\n",
    "                               class_list=CLS_LIST))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mental-corpus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>csv_paths</th>\n",
       "      <th>csv_files</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../raw_data/Out_Feature_CSVs/Train/Bad</td>\n",
       "      <td>IMG_9347_03.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../raw_data/Out_Feature_CSVs/Train/Bad</td>\n",
       "      <td>IMG_9336_03.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../raw_data/Out_Feature_CSVs/Train/Bad</td>\n",
       "      <td>54.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../raw_data/Out_Feature_CSVs/Train/Bad</td>\n",
       "      <td>IMG_9451_02.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../raw_data/Out_Feature_CSVs/Train/Bad</td>\n",
       "      <td>IMG_9451_03.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                csv_paths        csv_files  labels\n",
       "0  ../raw_data/Out_Feature_CSVs/Train/Bad  IMG_9347_03.csv       0\n",
       "1  ../raw_data/Out_Feature_CSVs/Train/Bad  IMG_9336_03.csv       0\n",
       "2  ../raw_data/Out_Feature_CSVs/Train/Bad           54.csv       0\n",
       "3  ../raw_data/Out_Feature_CSVs/Train/Bad  IMG_9451_02.csv       0\n",
       "4  ../raw_data/Out_Feature_CSVs/Train/Bad  IMG_9451_03.csv       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "geographic-casino",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create y_train and y_test as float64 type\n",
    "y_train = train_data['labels']/1.0\n",
    "y_test = test_data['labels']/1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "golden-action",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_list_of_lists(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.fillna(0, inplace=True)\n",
    "    list_of_lists = df.iloc[:,1:].values.tolist()\n",
    "    return list_of_lists\n",
    "\n",
    "def get_x(dataframe):\n",
    "  list_of_csv_files = [os.path.join(row['csv_paths'], row[\"csv_files\"]) for index, row in dataframe.iterrows()]\n",
    "  X_list = [csv_to_list_of_lists(f) for f in list_of_csv_files]\n",
    "  return X_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "administrative-gentleman",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create X_train and X_test\n",
    "X_train = get_x(train_data)\n",
    "X_test = get_x(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fitted-citizenship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130, 175, 2048)\n",
      "(34, 175, 2048)\n"
     ]
    }
   ],
   "source": [
    "#pad X_train so all arrays are of the same shape\n",
    "X_train_pad = pad_sequences(X_train, dtype='float32', padding='post', value=-1000)\n",
    "print(X_train_pad.shape)\n",
    "\n",
    "#pad X_test so all arrays are of the same shape\n",
    "X_test_pad = pad_sequences(X_test, dtype='float32', padding='post', value=-1000, maxlen=X_train_pad.shape[1])\n",
    "print(X_test_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "approved-decade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "interested-remedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_neurons=[256,128,64]\n",
    "neurons=[64,32,16]\n",
    "hyperparams = itertools.product(lstm_neurons,neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "outer-appendix",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "  rmsprop = optimizers.RMSprop(lr=0.0001)\n",
    "  model_LSTM = Sequential()\n",
    "  model_LSTM.add(layers.Masking(mask_value=-1000, input_shape=input_shape))\n",
    "  model_LSTM.add(layers.LSTM(128, activation='tanh', return_sequences=True))\n",
    "  model_LSTM.add(layers.Dropout(0.2))\n",
    "  model_LSTM.add(layers.LSTM(64, activation='tanh'))\n",
    "  model_LSTM.add(layers.Dense(64, activation='relu'))\n",
    "  model_LSTM.add(layers.Dense(32, activation='relu'))\n",
    "  model_LSTM.add(layers.Dense(16, activation='relu'))\n",
    "  model_LSTM.add(layers.Dense(8, activation='relu'))\n",
    "  model_LSTM.add(layers.Dense(4, activation='relu'))\n",
    "  model_LSTM.add(layers.Dense(2, activation='relu'))\n",
    "  model_LSTM.add(layers.Dense(1, activation='sigmoid'))\n",
    "  model_LSTM.compile(loss='binary_crossentropy', optimizer=rmsprop,metrics='accuracy')\n",
    "  return model_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "consistent-administration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 116ms/step - loss: 0.4015 - accuracy: 0.9154\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.1410 - accuracy: 0.5588\n",
      "train=0.9153845906257629, test= 0.5588235259056091\n"
     ]
    }
   ],
   "source": [
    "#Fitting the model to the train set\n",
    "\n",
    "model = build_model(input_shape=(X_train_pad.shape[1], X_train_pad.shape[2]))\n",
    "es = EarlyStopping(patience=20)\n",
    "\n",
    "model.fit(X_train_pad, y_train, \n",
    "          epochs=500, \n",
    "          batch_size=32, \n",
    "          verbose=0, \n",
    "          callbacks = [es],\n",
    "          validation_split=0.2,\n",
    "          shuffle=True)\n",
    "print(f'train={model.evaluate(X_train_pad, y_train)[1]}, test= {model.evaluate(X_test_pad, y_test)[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-virginia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model on the train set\n",
    "model.evaluate(X_train_pad, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geological-roman",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model on the test set\n",
    "model.evaluate(X_test_pad, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-kernel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions of the test set compared to the actuals\n",
    "model.predict(X_test_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-environment",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-plate",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"my_model\")\n",
    "#model.save_weights(\"weights.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
